{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "370d7b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)                      # Python 随机模块\n",
    "    np.random.seed(seed)                   # Numpy 随机模块\n",
    "    torch.manual_seed(seed)                # PyTorch CPU 随机种子\n",
    "    torch.cuda.manual_seed(seed)           # PyTorch 当前 GPU 随机种子\n",
    "    torch.cuda.manual_seed_all(seed)       # 所有 GPU 随机种子（多卡时）\n",
    "\n",
    "    # 保证每次返回的卷积算法确定（固定 cudnn 的随机性）\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "# 调用种子设置\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75aa7da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30dB SNR的样本总数：98304\n",
      "30dB SNR的样本总数：98304\n",
      "30dB SNR训练集大小：88473 | 测试集大小：9831\n",
      "输入形状：torch.Size([2, 1024]) | 标签示例：16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 数据集路径\n",
    "dataset_path = \"/home/free/prj2/finn/GOLD_XYZ_OSC.0001_1024.hdf5\"\n",
    "\n",
    "class RadioMLDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", sample_ratio=0.1, target_snr=30):\n",
    "        \"\"\"\n",
    "        新增target_snr参数：筛选指定SNR的样本（如30dB）\n",
    "        \"\"\"\n",
    "        assert os.path.exists(dataset_path), f\"数据集不存在：{dataset_path}\"\n",
    "        self.h5_file = h5py.File(dataset_path, 'r')\n",
    "        \n",
    "        # 读取所有样本的SNR值（Z维度）\n",
    "        self.snr_all = self.h5_file['Z'][:].squeeze()  # 形状：(N,)，每个样本的SNR值\n",
    "        self.target_snr = target_snr\n",
    "        \n",
    "        # 步骤1：筛选出30dB SNR的样本索引\n",
    "        snr_indices = np.where(self.snr_all == self.target_snr)[0]\n",
    "        print(f\"30dB SNR的样本总数：{len(snr_indices)}\")\n",
    "        \n",
    "        # 步骤2：按比例抽样（如10%），若样本不足则全部使用\n",
    "        sample_num = min(int(len(snr_indices)*sample_ratio), len(snr_indices))\n",
    "        sampled_indices = np.random.choice(snr_indices, size=sample_num, replace=False)\n",
    "        \n",
    "        # 步骤3：划分训练/测试集（9:1）\n",
    "        np.random.shuffle(sampled_indices)\n",
    "        split_idx = int(0.9 * len(sampled_indices))\n",
    "        self.indices = sampled_indices[:split_idx] if split == \"train\" else sampled_indices[split_idx:]\n",
    "        \n",
    "        # 读取数据和标签（仅筛选后的样本）\n",
    "        self.data = self.h5_file['X']  # (N, 1024, 2)\n",
    "        self.labels = np.argmax(self.h5_file['Y'][:], axis=1)  # 0-23\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        # 读取样本并转置为(2, 1024)，归一化\n",
    "        x = self.data[real_idx].astype(np.float32).transpose(1, 0)\n",
    "        x = x / np.max(np.abs(x))  # 信号归一化\n",
    "        y = self.labels[real_idx]\n",
    "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.h5_file.close()\n",
    "\n",
    "# 创建30dB SNR的数据集\n",
    "train_dataset = RadioMLDataset(split=\"train\", sample_ratio=1.0, target_snr=30)  # sample_ratio=1.0：使用所有30dB样本\n",
    "test_dataset = RadioMLDataset(split=\"test\", sample_ratio=1.0, target_snr=30)\n",
    "\n",
    "# 数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"30dB SNR训练集大小：{len(train_dataset)} | 测试集大小：{len(test_dataset)}\")\n",
    "print(f\"输入形状：{train_dataset[0][0].shape} | 标签示例：{train_dataset[0][1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a336c93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VGG10_1D(nn.Module):\n",
    "    def __init__(self, num_classes=24, in_channels=2):\n",
    "        super(VGG10_1D, self).__init__()\n",
    "        # 卷积块1: 2→64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 卷积块2: 64→128\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 卷积块3: 128→256\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 卷积块4: 256→512\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 卷积块5: 512→512（VGG10共10层卷积）\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 全连接层（输入维度计算：1024经过5次池化→1024/(2^5)=32，512*32=16384）\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 32, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VGG10_1D(num_classes=24).to(device)\n",
    "print(f\"Model initialized on {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d846933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\n",
      "Train Loss: 1.1811 | Train Acc: 51.51%\n",
      "Test Loss: 0.8223 | Test Acc: 62.12%\n",
      "Best model saved (Acc: 62.12%)\n",
      "Epoch [2/20]\n",
      "Train Loss: 0.8869 | Train Acc: 61.27%\n",
      "Test Loss: 0.7337 | Test Acc: 66.45%\n",
      "Best model saved (Acc: 66.45%)\n",
      "Epoch [3/20]\n",
      "Train Loss: 0.7524 | Train Acc: 66.45%\n",
      "Test Loss: 0.6213 | Test Acc: 69.21%\n",
      "Best model saved (Acc: 69.21%)\n",
      "Epoch [4/20]\n",
      "Train Loss: 0.6315 | Train Acc: 70.60%\n",
      "Test Loss: 0.5024 | Test Acc: 75.03%\n",
      "Best model saved (Acc: 75.03%)\n",
      "Epoch [5/20]\n",
      "Train Loss: 0.5646 | Train Acc: 73.15%\n",
      "Test Loss: 0.4817 | Test Acc: 75.74%\n",
      "Best model saved (Acc: 75.74%)\n",
      "Epoch [6/20]\n",
      "Train Loss: 0.5208 | Train Acc: 74.93%\n",
      "Test Loss: 0.4424 | Test Acc: 78.67%\n",
      "Best model saved (Acc: 78.67%)\n",
      "Epoch [7/20]\n",
      "Train Loss: 0.4910 | Train Acc: 76.12%\n",
      "Test Loss: 0.4255 | Test Acc: 78.74%\n",
      "Best model saved (Acc: 78.74%)\n",
      "Epoch [8/20]\n",
      "Train Loss: 0.4708 | Train Acc: 76.98%\n",
      "Test Loss: 0.3606 | Test Acc: 82.02%\n",
      "Best model saved (Acc: 82.02%)\n",
      "Epoch [9/20]\n",
      "Train Loss: 0.4431 | Train Acc: 78.63%\n",
      "Test Loss: 0.3576 | Test Acc: 83.22%\n",
      "Best model saved (Acc: 83.22%)\n",
      "Epoch [10/20]\n",
      "Train Loss: 0.3970 | Train Acc: 81.29%\n",
      "Test Loss: 0.3042 | Test Acc: 84.22%\n",
      "Best model saved (Acc: 84.22%)\n",
      "Epoch [11/20]\n",
      "Train Loss: 0.2776 | Train Acc: 85.95%\n",
      "Test Loss: 0.2125 | Test Acc: 89.39%\n",
      "Best model saved (Acc: 89.39%)\n",
      "Epoch [12/20]\n",
      "Train Loss: 0.2543 | Train Acc: 86.92%\n",
      "Test Loss: 0.2092 | Test Acc: 88.73%\n",
      "Epoch [13/20]\n",
      "Train Loss: 0.2438 | Train Acc: 87.45%\n",
      "Test Loss: 0.2004 | Test Acc: 89.96%\n",
      "Best model saved (Acc: 89.96%)\n",
      "Epoch [14/20]\n",
      "Train Loss: 0.2342 | Train Acc: 88.06%\n",
      "Test Loss: 0.1878 | Test Acc: 89.88%\n",
      "Epoch [15/20]\n",
      "Train Loss: 0.2282 | Train Acc: 88.40%\n",
      "Test Loss: 0.1862 | Test Acc: 90.98%\n",
      "Best model saved (Acc: 90.98%)\n",
      "Epoch [16/20]\n",
      "Train Loss: 0.2198 | Train Acc: 89.09%\n",
      "Test Loss: 0.1797 | Test Acc: 90.95%\n",
      "Epoch [17/20]\n",
      "Train Loss: 0.2150 | Train Acc: 89.37%\n",
      "Test Loss: 0.1736 | Test Acc: 92.26%\n",
      "Best model saved (Acc: 92.26%)\n",
      "Epoch [18/20]\n",
      "Train Loss: 0.2081 | Train Acc: 89.90%\n",
      "Test Loss: 0.1648 | Test Acc: 92.57%\n",
      "Best model saved (Acc: 92.57%)\n",
      "Epoch [19/20]\n",
      "Train Loss: 0.2023 | Train Acc: 90.25%\n",
      "Test Loss: 0.1643 | Test Acc: 92.38%\n",
      "Epoch [20/20]\n",
      "Train Loss: 0.1973 | Train Acc: 90.71%\n",
      "Test Loss: 0.1537 | Test Acc: 93.24%\n",
      "Best model saved (Acc: 93.24%)\n",
      "Training finished. Best Test Acc: 93.24%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 损失函数与优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # 学习率衰减\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# 测试函数\n",
    "def test_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    return avg_loss, accuracy\n",
    "num_epochs = 20\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_loss, test_acc = test_epoch(model, test_loader, criterion, device)\n",
    "    scheduler.step()  # 更新学习率\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    # 保存最优模型\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), \"vgg10_1d_best.pth\")\n",
    "        print(f\"Best model saved (Acc: {best_acc:.2f}%)\")\n",
    "\n",
    "print(f\"Training finished. Best Test Acc: {best_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b858b199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX模型导出完成：vgg10_1d_finn.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义VGG10 1D模型结构（需与训练时一致）\n",
    "class VGG10_1D(nn.Module):\n",
    "    def __init__(self, num_classes=24, in_channels=2):\n",
    "        super(VGG10_1D, self).__init__()\n",
    "        # 卷积块1: 2→64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 卷积块2: 64→128\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 卷积块3: 128→256\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 卷积块4: 256→512\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 卷积块5: 512→512\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # 全连接层\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 32, 4096),  # 1024/(2^5)=32\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.0),  # FINN建议移除Dropout\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.0),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = x.view(x.size(0), -1)  # 展平\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型并加载权重\n",
    "device = torch.device(\"cpu\")  # FINN导出建议用CPU\n",
    "model = VGG10_1D(num_classes=24).to(device)\n",
    "model.load_state_dict(torch.load(\"vgg10_1d_best.pth\", map_location=device))\n",
    "model.eval()  # 评估模式（关闭Dropout/BatchNorm训练态）\n",
    "\n",
    "# 导出ONNX（FINN要求静态输入形状，batch_size设为1）\n",
    "input_shape = (1, 2, 1024)  # [batch, in_channels, seq_len]\n",
    "dummy_input = torch.randn(input_shape).to(device)\n",
    "\n",
    "# 导出ONNX（关键参数：opset_version=11，去掉动态维度）\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"vgg10_1d_finn.onnx\",  # 输出文件名\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    opset_version=11,  # FINN兼容的ONNX版本\n",
    "    do_constant_folding=True,  # 常量折叠优化\n",
    "    dynamic_axes=None  # 禁用动态维度（FINN要求静态形状）\n",
    ")\n",
    "\n",
    "print(\"ONNX模型导出完成：vgg10_1d_finn.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd188ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from transformation.base import Transformation\n",
    "from transformation.general import RemoveUnusedTensors\n",
    "from transformation.infer_shapes import InferShapes\n",
    "\n",
    "def get_by_name(container, name, name_field=\"name\"):\n",
    "    \"\"\"Return item from container by .name field if it exists, None otherwise.\n",
    "    Will throw an Exception if multiple items are found, since this violates the\n",
    "    ONNX standard.\"\"\"\n",
    "    names = [getattr(x, name_field) for x in container]\n",
    "\n",
    "    inds = [i for i, e in enumerate(names) if e == name]\n",
    "    if len(inds) > 1:\n",
    "        raise Exception(\"Found multiple get_by_name matches, undefined behavior\")\n",
    "    elif len(inds) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        ind = inds[0]\n",
    "        return container[ind]\n",
    "\n",
    "def _find_invalid_nodes(model):\n",
    "    \"\"\"\n",
    "    Check whether the graph contains any node types that are not supported by the\n",
    "    Change3Dto4DTensors transformation.\n",
    "\n",
    "    \"\"\"\n",
    "    valid_nodes = [\n",
    "        \"Add\",\n",
    "        \"Mul\",\n",
    "        \"BatchNormalization\",\n",
    "        \"MultiThreshold\",\n",
    "        \"Conv\",\n",
    "        \"Transpose\",\n",
    "        \"LogSoftmax\",\n",
    "        \"ArgMax\",\n",
    "        \"Div\",\n",
    "        \"TopK\",\n",
    "        \"MatMul\",\n",
    "        \"Flatten\",\n",
    "        \"Reshape\",\n",
    "        \"MaxPool\",\n",
    "        \"Relu\",    # 无维度属性，仅逐元素运算，不影响4D转换\n",
    "        \"Constant\",# 常量节点，无维度依赖\n",
    "        \"Gemm\"     # 矩阵乘法，1D场景下可兼容4D张量\n",
    "    ]\n",
    "    invalid_nodes = []\n",
    "    for n in model.graph.node:\n",
    "        node_op_type = n.op_type\n",
    "        if node_op_type in valid_nodes:\n",
    "            continue\n",
    "        else:\n",
    "            invalid_nodes.append(node_op_type)\n",
    "\n",
    "    return invalid_nodes\n",
    "\n",
    "\n",
    "class Change3DTo4DTensors(Transformation):\n",
    "    \"\"\"\n",
    "    Replaces 3D tensors with 4D tensors assuming the following format:\n",
    "    [N, C, H] -> [N, C, H, 1].\n",
    "    The attributes of a (specific) set of supported nodes are changed accordingly.\n",
    "    If the graph contains unsupported nodes, a warning is raised and the transformation\n",
    "    is not applied.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(self, model):\n",
    "        graph_modified = False\n",
    "\n",
    "        invalid_nodes = _find_invalid_nodes(model)\n",
    "        if len(invalid_nodes) > 0:\n",
    "            warnings.warn(\n",
    "                \"Transformation is not applied,\\\n",
    "                 found unsupported nodes in the graph: {}.\".format(\n",
    "                    invalid_nodes\n",
    "                )\n",
    "            )\n",
    "            return (model, graph_modified)\n",
    "\n",
    "        # Infer the shapes of each tensor, remove unused tensors\n",
    "        # and give each tensor a readable name\n",
    "        model = model.transform(InferShapes())\n",
    "        model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "        # This list contains all nodes with initializers that need to be converted\n",
    "        nodes_with_initializers = [\"Mul\", \"Conv\", \"Add\", \"Div\", \"Reshape\"]\n",
    "        # Obtain a list of initializer names (used to filter out only value infos)\n",
    "        initializers_names = [x.name for x in model.graph.initializer]\n",
    "\n",
    "        all_tensors = {}\n",
    "        # Extract the inputs\n",
    "        all_tensors = {\n",
    "            **all_tensors,\n",
    "            **{\n",
    "                x.name: [x.type.tensor_type.elem_type, model.get_tensor_shape(x.name)]\n",
    "                for x in model.graph.input\n",
    "            },\n",
    "        }\n",
    "        # Extract only the output tensors\n",
    "        all_tensors = {\n",
    "            **all_tensors,\n",
    "            **{\n",
    "                x.name: [x.type.tensor_type.elem_type, model.get_tensor_shape(x.name)]\n",
    "                for x in model.graph.value_info\n",
    "                if x.name not in initializers_names\n",
    "            },\n",
    "        }\n",
    "        # Extract only initializers from nodes that are relevant for conversion\n",
    "        all_tensors = {\n",
    "            **all_tensors,\n",
    "            **{\n",
    "                x.name: [x.data_type, x.dims]\n",
    "                for x in model.graph.initializer\n",
    "                if model.find_consumer(x.name).op_type in nodes_with_initializers\n",
    "            },\n",
    "        }\n",
    "        # Extract the outputs\n",
    "        all_tensors = {\n",
    "            **all_tensors,\n",
    "            **{\n",
    "                x.name: [x.type.tensor_type.elem_type, model.get_tensor_shape(x.name)]\n",
    "                for x in model.graph.output\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # The list below contains tensor names that are the output of nodes that\n",
    "        # reduce the tensor's dimension. The shape of these tensors also needs\n",
    "        # to be extended\n",
    "        tensors_reduced_dimension = []\n",
    "        for n in model.graph.node:\n",
    "            node_op_type = n.op_type\n",
    "            input_shape = model.get_tensor_shape(n.input[0])\n",
    "            # Find tensors that are the output of nodes that reduce the dimension\n",
    "            if node_op_type == \"ArgMax\":\n",
    "                keep_dims = get_by_name(n.attribute, \"keepdims\", \"name\").i\n",
    "                if len(input_shape) == 3 and keep_dims == 0:\n",
    "                    node_out = n.output\n",
    "                    for n_o in node_out:\n",
    "                        tensors_reduced_dimension.append(n_o)\n",
    "            # Each node from the list of supported nodes is made compatible\n",
    "            # with 4D tensors\n",
    "            if node_op_type == \"Transpose\":\n",
    "                perm = get_by_name(n.attribute, \"perm\", \"name\").ints\n",
    "                if (\n",
    "                    len(perm) == 3\n",
    "                ):  # Meaning that the transpose operation was on a 3D tensor\n",
    "                    perm.append(3)  # append 4th dimension\n",
    "            elif node_op_type in [\"ArgMax\", \"LogSoftMax\", \"TopK\", \"Flatten\"]:\n",
    "                axis = get_by_name(n.attribute, \"axis\", \"name\")\n",
    "                if len(input_shape) == 3 and axis.i < 0:\n",
    "                    axis.i = 3 + axis.i  # count dimensions from the front\n",
    "            elif node_op_type == \"Conv\":\n",
    "                dilations = get_by_name(n.attribute, \"dilations\", \"name\").ints\n",
    "                kernel_shape = get_by_name(n.attribute, \"kernel_shape\", \"name\").ints\n",
    "                pads = get_by_name(n.attribute, \"pads\", \"name\").ints\n",
    "                strides = get_by_name(n.attribute, \"strides\", \"name\").ints\n",
    "                if len(dilations) == 1:  # we must add another dimension to it\n",
    "                    dilations.append(\n",
    "                        1\n",
    "                    )  # only equal dilation value along each spatial axis is supported\n",
    "                if len(kernel_shape) == 1:  # we must add another dimension to it\n",
    "                    kernel_shape.append(1)\n",
    "                if (\n",
    "                    len(pads) == 2\n",
    "                ):  # pads = [x1_begin, x1_end] --> [x1_begin, x2_begin, x1_end, x2_end]\n",
    "                    pads.insert(1, 0)\n",
    "                    pads.append(0)\n",
    "                if len(strides) == 1:  # strides = [stride_h, stride_w]\n",
    "                    strides.append(1)\n",
    "            elif node_op_type == \"MaxPool\":\n",
    "                kernel_shape = get_by_name(n.attribute, \"kernel_shape\", \"name\").ints\n",
    "                pads = get_by_name(n.attribute, \"pads\", \"name\").ints\n",
    "                strides = get_by_name(n.attribute, \"strides\", \"name\").ints\n",
    "                if len(kernel_shape) == 1:  # we must add another dimension to it\n",
    "                    kernel_shape.append(1)\n",
    "                if (\n",
    "                    len(pads) == 2\n",
    "                ):  # pads = [x1_begin, x1_end] --> [x1_begin, x2_begin, x1_end, x2_end]\n",
    "                    pads.insert(1, 0)\n",
    "                    pads.append(0)\n",
    "                if len(strides) == 1:  # strides = [stride_h, stride_w]\n",
    "                    strides.append(1)\n",
    "\n",
    "        # Change format of each input/value_info/output tensor\n",
    "        for k, v in all_tensors.items():\n",
    "            tensor_type = v[0]\n",
    "            shape = v[1]\n",
    "            # Add extra dimension for tensors that either:\n",
    "            # 1) Have 3 dimensions ( (N,C,H) -> (N,C,H,1) )\n",
    "            # 2) Come after operations that reduce their dimension: e.g. {Argmax, ...}\n",
    "            if len(shape) == 3 or k in tensors_reduced_dimension:\n",
    "                shape.append(1)\n",
    "                model.set_tensor_shape(k, shape, tensor_type)\n",
    "\n",
    "        return (model, graph_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e85024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.builder.build_dataflow_config import DataflowBuildConfig\n",
    "from qonnx.transformation.general import GiveUniqueNodeNames\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "# 导入自定义的Transformation类\n",
    "\n",
    "\n",
    "def step_pre_streamline(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
    "    model = model.transform(Change3DTo4DTensors())\n",
    "    # 吸收标量运算到TopK层\n",
    "    model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "    return model\n",
    "def step_convert_final_layers(model: ModelWrapper, cfg: DataflowBuildConfig):\n",
    "    model = model.transform(to_hw.InferChannelwiseLinearLayer())\n",
    "    model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0bcb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building dataflow accelerator from vgg10_1d_finn.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_root\n",
      "Final outputs will be generated in output_vgg10_1d_finn_PYNQ-Z2\n",
      "Build log is at output_vgg10_1d_finn_PYNQ-Z2/build_dataflow.log\n",
      "Running step: step_tidy_up [1/20]\n",
      "Running step: step_pre_streamline [2/20]\n",
      "Running step: step_streamline [3/20]\n",
      "Running step: step_convert_to_hw [4/20]\n",
      "Running step: step_convert_final_layers [5/20]\n",
      "Running step: step_create_dataflow_partition [6/20]\n",
      "> \u001b[0;32m/home/free/prj2/finn/deps/qonnx/src/qonnx/transformation/create_generic_partitions.py\u001b[0m(119)\u001b[0;36mapply\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    117 \u001b[0;31m                    \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    118 \u001b[0;31m                        assert (\n",
      "\u001b[0m\u001b[0;32m--> 119 \u001b[0;31m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitioning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpartition_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m                        ), \"\"\"cycle-free graph violated: partition depends on itself\"\"\"\n",
      "\u001b[0m\u001b[0;32m    121 \u001b[0;31m                        \u001b[0;31m# print(node)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/free/prj2/finn/src/finn/builder/build_dataflow.py\", line 158, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/home/free/prj2/finn/src/finn/builder/build_dataflow_steps.py\", line 372, in step_create_dataflow_partition\n",
      "    parent_model = model.transform(\n",
      "  File \"/home/free/prj2/finn/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 140, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/free/prj2/finn/src/finn/transformation/fpgadataflow/create_dataflow_partition.py\", line 80, in apply\n",
      "    parent_model = model.transform(\n",
      "  File \"/home/free/prj2/finn/deps/qonnx/src/qonnx/core/modelwrapper.py\", line 140, in transform\n",
      "    (transformed_model, model_was_changed) = transformation.apply(transformed_model)\n",
      "  File \"/home/free/prj2/finn/deps/qonnx/src/qonnx/transformation/create_generic_partitions.py\", line 119, in apply\n",
      "    self.partitioning(node) != partition_id\n",
      "AssertionError: cycle-free graph violated: partition depends on itself\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2020, Xilinx\n",
    "# All rights reserved.\n",
    "# （省略BSD协议声明，实际使用时需保留）\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "from finn.util.basic import alveo_default_platform\n",
    "\n",
    "\n",
    "\n",
    "# 模型名称与平台配置\n",
    "model_name = \"vgg10_1d_finn\"\n",
    "zynq_platforms = [\"PYNQ-Z2\"]  # 目标平台为PYNQ-Z2\n",
    "alveo_platforms = []\n",
    "platforms_to_build = zynq_platforms + alveo_platforms\n",
    "\n",
    "# 平台到Shell流类型的映射\n",
    "def platform_to_shell(platform):\n",
    "    if platform in zynq_platforms:\n",
    "        return build_cfg.ShellFlowType.VIVADO_ZYNQ\n",
    "    elif platform in alveo_platforms:\n",
    "        return build_cfg.ShellFlowType.VITIS_ALVEO\n",
    "    else:\n",
    "        raise Exception(f\"Unknown platform: {platform}\")\n",
    "\n",
    "# 选择目标时钟周期（PYNQ-Z2推荐7ns~10ns，此处选8ns即125MHz，稳定性优先）\n",
    "def select_clk_period(platform):\n",
    "    if platform == \"PYNQ-Z2\":\n",
    "        return 8.0  # 125MHz\n",
    "    else:\n",
    "        return 4.0  # 其他平台默认250MHz\n",
    "\n",
    "# 构建步骤选择（适配PYNQ-Z2）\n",
    "def select_build_steps(platform):\n",
    "    steps = [\n",
    "        \"step_tidy_up\",\n",
    "        step_pre_streamline,\n",
    "        \"step_streamline\",\n",
    "        \"step_convert_to_hw\",\n",
    "        step_convert_final_layers,\n",
    "        \"step_create_dataflow_partition\",\n",
    "        \"step_specialize_layers\",\n",
    "        \"step_target_fps_parallelization\",\n",
    "        \"step_apply_folding_config\",\n",
    "        \"step_minimize_bit_width\",\n",
    "        \"step_generate_estimate_reports\",\n",
    "        \"step_hw_codegen\",\n",
    "        \"step_hw_ipgen\",\n",
    "        \"step_set_fifo_depths\",\n",
    "        \"step_create_stitched_ip\",\n",
    "        \"step_measure_rtlsim_performance\",  # 可选，若需要RTLSIM性能测试\n",
    "        \"step_out_of_context_synthesis\",\n",
    "        \"step_synthesize_bitfile\",\n",
    "        \"step_make_pynq_driver\",\n",
    "        \"step_deployment_package\",\n",
    "    ]\n",
    "    return steps\n",
    "\n",
    "# 创建发布目录\n",
    "os.makedirs(\"release\", exist_ok=True)\n",
    "\n",
    "# 遍历目标平台构建\n",
    "for platform_name in platforms_to_build:\n",
    "    shell_flow_type = platform_to_shell(platform_name)\n",
    "    # PYNQ-Z2作为Zynq平台，直接使用板名作为发布目录名\n",
    "    release_platform_name = platform_name\n",
    "    platform_dir = f\"release/{release_platform_name}\"\n",
    "    os.makedirs(platform_dir, exist_ok=True)\n",
    "\n",
    "    vitis_opt = build_cfg.VitisOptStrategyCfg.SIZE\n",
    "\n",
    "    cfg = build_cfg.DataflowBuildConfig(\n",
    "        steps=select_build_steps(platform_name),\n",
    "        output_dir=f\"output_{model_name}_{release_platform_name}\",\n",
    "        synth_clk_period_ns=select_clk_period(platform_name),\n",
    "        board=platform_name,\n",
    "        shell_flow_type=shell_flow_type,\n",
    "        vitis_platform=None,  # PYNQ-Z2为Vivado Zynq流，无需Vitis平台\n",
    "    # 层特化配置文件（若未创建，先注释掉这行，避免文件找不到报错）\n",
    "    # specialize_layers_config_file=f\"specialize_layers_config/{platform_name}_specialize_layers.json\",\n",
    "    # 折叠配置文件（必须存在，即使是空文件）\n",
    "        folding_config_file=f\"folding_config/{platform_name}_folding_config.json\",\n",
    "        split_large_fifos=True,  # 拆分大FIFO以适配PYNQ-Z2的BRAM资源\n",
    "        standalone_thresholds=True,\n",
    "    # 替换为你版本支持的枚举值（SIZE适配Z2资源）\n",
    "        vitis_opt_strategy=vitis_opt,\n",
    "    # 生成的输出产物（重点包含PYNQ驱动和部署包）\n",
    "        generate_outputs=[\n",
    "            build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "            build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "            build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "            build_cfg.DataflowOutputType.BITFILE,\n",
    "            build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "            build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "    ],\n",
    "   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# 模型文件路径（根目录）\n",
    "model_file = \"vgg10_1d_finn.onnx\"\n",
    "if not os.path.exists(model_file):\n",
    "        raise FileNotFoundError(f\"Model file {model_file} not found!\")\n",
    "\n",
    "    # 执行数据流构建\n",
    "build.build_dataflow_cfg(model_file, cfg)\n",
    "\n",
    "    # 复制产物到发布目录\n",
    "bitfile_gen_dir = os.path.join(cfg.output_dir, \"bitfile\")\n",
    "files_to_copy = [\n",
    "        \"finn-accel.bit\",    # 比特流文件\n",
    "        \"finn-accel.hwh\",    # 硬件描述文件（PYNQ需要）\n",
    "        \"finn-accel.xclbin\", # Alveo用，PYNQ-Z2可忽略\n",
    "    ]\n",
    "for f in files_to_copy:\n",
    "        src = os.path.join(bitfile_gen_dir, f)\n",
    "        if os.path.exists(src):\n",
    "            dst = os.path.join(platform_dir, f.replace(\"finn-accel\", model_name))\n",
    "            shutil.copy(src, dst)\n",
    "            print(f\"Copied {f} to {dst}\")\n",
    "\n",
    "    # 复制运行时权重和PYNQ驱动\n",
    "weight_gen_dir = os.path.join(cfg.output_dir, \"driver\", \"runtime_weights\")\n",
    "if os.path.exists(weight_gen_dir):\n",
    "        weight_dst_dir = os.path.join(platform_dir, f\"{model_name}_runtime_weights\")\n",
    "        if os.path.exists(weight_dst_dir):\n",
    "            shutil.rmtree(weight_dst_dir)\n",
    "        shutil.copytree(weight_gen_dir, weight_dst_dir)\n",
    "        print(f\"Copied runtime weights to {weight_dst_dir}\")\n",
    "\n",
    "driver_gen_dir = os.path.join(cfg.output_dir, \"driver\")\n",
    "driver_files = [\"finn_driver.py\", \"finn_util.py\"]  # PYNQ驱动核心文件\n",
    "for df in driver_files:\n",
    "        src = os.path.join(driver_gen_dir, df)\n",
    "        if os.path.exists(src):\n",
    "            dst = os.path.join(platform_dir, df.replace(\"finn\", model_name))\n",
    "            shutil.copy(src, dst)\n",
    "            print(f\"Copied PYNQ driver {df} to {dst}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
